# Step 1: Install required packages
!pip install flask flask-cors pyngrok torch torchvision timm --quiet

# Step 2: Import necessary libraries
from flask import Flask, request, jsonify
from flask_cors import CORS
import torch
import timm
from torchvision import transforms, datasets
from torch.utils.data import DataLoader
import torch.nn as nn
import torch.optim as optim
from PIL import Image
import io
from pyngrok import ngrok
import subprocess
import time
import threading
from google.colab import drive
import os
import shutil
import logging

# Step 3: Set up logging
logging.basicConfig(filename='/content/api.log', level=logging.INFO,
                    format='%(asctime)s - %(levelname)s - %(message)s')

# Step 4: Mount Google Drive
drive.mount('/content/drive', force_remount=True)

# Step 5: Free up port 5000 and kill ngrok
subprocess.run(["fuser", "-k", "5000/tcp"])
!pkill ngrok

# Step 6: Set up ngrok authtoken
!ngrok config add-authtoken 2watLjzGUsohd0DZihR8TDe7qAN_3CZjwVrXzt6L4uEnUKZci

# Step 7: Start ngrok in a separate thread
def start_ngrok():
    try:
        public_url = ngrok.connect(5000)
        logging.info(f"Ngrok URL: {public_url}")
        print(f"ðŸ”— Ngrok URL (Update in config.php): {public_url}/api/test")
        print(f"Visit {public_url} to see 'Your API is running!'")
        print(f"Test with Postman: POST {public_url}/api/test, form-data, key='image', value=<Plant image>")
    except Exception as e:
        logging.error(f"Ngrok error: {str(e)}")
        print(f"Ngrok error: {str(e)}")

thread = threading.Thread(target=start_ngrok)
thread.start()
time.sleep(5)

# Step 8: Set up Flask app
app = Flask(__name__)
CORS(app, resources={r"/*": {"origins": ["http://localhost", "http://127.0.0.1"]}})

# Step 9: Root route for testing
@app.route('/')
def home():
    logging.info("Root endpoint accessed")
    return "Your API is running!"

# Global Variables
model = None
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model_path = '/content/drive/MyDrive/plantdisease_model.pth'

# Step 10: Dataset Setup
def setup_plant_disease_dataset():
    dataset_path = '/content/drive/MyDrive/Datasets/data'
    binary_path = '/content/PlantDiseaseTest_Binary'

    possible_paths = [
        '/content/drive/MyDrive/Datasets/data',
        '/content/drive/MyDrive/Datasets/Data',
        '/content/drive/MyDrive/Data',
        '/content/drive/MyDrive/Datasets/PlantDiseaseTest'
    ]

    for path in possible_paths:
        if os.path.exists(path):
            dataset_path = path
            logging.info(f"Found dataset at: {dataset_path}")
            print(f"Using dataset path: {dataset_path}")
            break
    else:
        print(f"Dataset not found. Upload it to Google Drive at:")
        print(f"/content/drive/MyDrive/Datasets/data OR Data OR PlantDiseaseTest")
        raise FileNotFoundError("Dataset not found.")

    subfolders = [f for f in os.listdir(dataset_path) if os.path.isdir(os.path.join(dataset_path, f))]
    if not subfolders:
        raise FileNotFoundError(f"No subfolders found in {dataset_path}")

    os.makedirs(binary_path, exist_ok=True)
    os.makedirs(os.path.join(binary_path, 'healthy'), exist_ok=True)
    os.makedirs(os.path.join(binary_path, 'diseased'), exist_ok=True)

    for class_folder in os.listdir(dataset_path):
        class_path = os.path.join(dataset_path, class_folder)
        if os.path.isdir(class_path):
            target_folder = 'healthy' if 'healthy' in class_folder.lower() else 'diseased'
            for img_file in os.listdir(class_path):
                if img_file.endswith(('.jpg', '.jpeg', '.png')):
                    src = os.path.join(class_path, img_file)
                    dst = os.path.join(binary_path, target_folder, img_file)
                    shutil.copy(src, dst)

    print("Dataset prepared!")

# Step 11: Train Model (ViT)
def train_model():
    transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])

    dataset = datasets.ImageFolder('/content/PlantDiseaseTest_Binary', transform=transform)
    train_loader = DataLoader(dataset, batch_size=32, shuffle=True)

    model = timm.create_model('vit_base_patch16_224', pretrained=True, num_classes=2)
    model = model.to(device)

    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=0.001)

    for epoch in range(5):
        model.train()
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
        print(f"Epoch {epoch+1}, Loss: {loss.item()}")

    torch.save(model.state_dict(), model_path)
    print("Model trained and saved!")
    return model

# Step 12: Load Model (Auto-detect ResNet/ViT)
def load_model():
    if not os.path.exists(model_path):
        print("Model not found! Training new model...")
        setup_plant_disease_dataset()
        return train_model()

    try:
        # Try loading with ResNet18
        model = timm.create_model('resnet18', pretrained=False, num_classes=2)
        model.load_state_dict(torch.load(model_path, map_location=device))
        model.to(device)
        model.eval()
        print("Loaded model with ResNet18 architecture.")
        return model
    except RuntimeError as e:
        print("ResNet18 failed, trying ViT...")
        try:
            model = timm.create_model('vit_base_patch16_224', pretrained=False, num_classes=2)
            model.load_state_dict(torch.load(model_path, map_location=device))
            model.to(device)
            model.eval()
            print("Loaded model with ViT architecture.")
            return model
        except RuntimeError as e:
            print("ViT also failed! Please retrain.")
            setup_plant_disease_dataset()
            return train_model()

# Load the model
model = load_model()

# Step 13: Define image transformations
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

# Step 14: Prediction Endpoint
@app.route('/api/test', methods=['POST'])
def predict():
    try:
        if 'image' not in request.files:
            return jsonify({"error": "No image provided"}), 400

        file = request.files['image']
        if file.filename == '':
            return jsonify({"error": "No image selected"}), 400

        img = Image.open(file.stream)

        if img.mode != 'RGB':
            img = img.convert('RGB')

        img = transform(img).unsqueeze(0).to(device)

        with torch.no_grad():
            output = model(img)
            probabilities = torch.softmax(output, dim=1)
            _, predicted = torch.max(output, 1)

            prediction = "diseased" if predicted.item() == 1 else "healthy"
            confidence = probabilities[0][predicted.item()].item()

        return jsonify({
            "prediction": prediction,
            "confidence": confidence,
            "probabilities": {
                "healthy": probabilities[0][0].item(),
                "diseased": probabilities[0][1].item()
            }
        })

    except Exception as e:
        return jsonify({"error": str(e)}), 500

# Step 15: Start Flask App
print("Starting Flask app...")
app.run(host='0.0.0.0', port=5000)
